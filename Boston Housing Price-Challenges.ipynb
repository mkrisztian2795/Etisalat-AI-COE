{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Boston House Prices\n",
    "In this notebook we are going to build a predictive regression model for esitmating the house prices in thousands of $ given some housing factors such as crime rate in neighborhood, number of schools %, lower status of the population etc.\n",
    "\n",
    "We will apply and elaborate the steps seen in the first Workshop (when applicable).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<dl></dl>\n",
    "<dl></dl>\n",
    "\n",
    "**Data Science Cycle:**\n",
    "\n",
    "    Data Understanding\n",
    "        0. Exploratory Data Analysis\n",
    "        \n",
    "    Data Preparation\n",
    "        1. Target Definition\n",
    "        2. Data Splitting\n",
    "        3. Feature Engineering\n",
    "    \n",
    "    Modeling\n",
    "        4. Variable Selection\n",
    "        5. Model Selection\n",
    "        6. Fine-tuning\n",
    "\n",
    "    Evaluation\n",
    "        7. Evaluation & Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boston Data\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Data Manipulation & analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Preparation\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "from boruta import BorutaPy \n",
    "import statsmodels.api as sm \n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "import xgboost as xgb\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "# Other Set Up\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style for displaying data\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Set style for plotting\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by exploring Boston data (Step 0) and setting the target (Step 1). \n",
    "\n",
    "Boston dataset is extremely common in machine learning experiments thus it is embedded in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed description of dataset and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset description\n",
    "print (boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pandas dataframe with objects in rows and features in columns, and define target.\n",
    "In this study, the target is already given as being the housing price (i.e. \"MEDV\", or the Median value of owner-occupied homes in $1000's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set panda dataframe\n",
    "boston_data = pd.DataFrame(boston.data)\n",
    "\n",
    "# Set column names\n",
    "boston_data.columns = boston.feature_names\n",
    "\n",
    "# Set target\n",
    "boston_target=pd.DataFrame(boston.target)\n",
    "boston_target.columns=['PRICE']\n",
    "\n",
    "# Merge into 1 data frame\n",
    "boston_df = pd.merge(boston_data,boston_target,left_index = True, right_index = True)\n",
    "\n",
    "# Set X and Y (features and target)\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "Y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check first few rows of data\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive statistics\n",
    "boston_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the features are categorical and some are continious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis Challenge:** Get more feeling about the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### INSERT CODE HERE ###\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### INSERT CODE HERE ###\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### INSERT CODE HERE ###\n",
    "########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is an academic data set, Data Modeling step is not required and Feature Engineering step is minimal as the data has already been carefully designed and cleaned.\n",
    "\n",
    "Let's split the data for testing purpose (Data Splitting step). We will set 10% of data aside. \n",
    "\n",
    "We can apply normalization to the range of 0 and 1 to make our data insensitive to the scale of features. (Feature Engineering step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "# Scale from 0 to 1\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test) #\n",
    "\n",
    "# This step is needed so that var selection methods can bring us column names - otherwise, \n",
    "# X_Train and Y_train are just numpy arrays, which is efficient for algorithm fitting but not for var selection \n",
    "X_train_df=pd.DataFrame(X_train)\n",
    "X_train_df.columns = boston.feature_names\n",
    "X_test_df=pd.DataFrame(X_test)\n",
    "X_test_df.columns = boston.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of features, let's visualize two of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(X_train_df.RM, Y_train, label=\"Train\")\n",
    "plt.scatter(X_test_df.RM, Y_test, c=\"r\", label=\"Test\")\n",
    "plt.xlabel(\"Average number of rooms per dwelling (Scaled)\")\n",
    "plt.ylabel(\"Price, $\")\n",
    "plt.legend(loc=\"lower right\", frameon=True)\n",
    "plt.subplot(122)\n",
    "plt.scatter(X_train_df.RAD, Y_train, label=\"Train\")\n",
    "plt.scatter(X_test_df.RAD, Y_test, c=\"r\", label=\"Test\")\n",
    "plt.xlabel(\"Index of accessibility to radial highways (Scaled)\")\n",
    "plt.ylabel(\"Price, $\")\n",
    "plt.legend(loc=\"lower right\", frameon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Now our data is ready, we can start modeling steps.\n",
    "\n",
    "**Variable Selection Challenge:** Try out different methods to decide which features to keep or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### INSERT CODE HERE ###\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### INSERT CODE HERE ###\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite original df-s with selected variables \n",
    "# In the two lines of code below, remove variables to exclude (if any)\n",
    "X_train = X_train_df[['CRIM', 'NOX', 'INDUS','RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT','ZN','CHAS','RAD']]\n",
    "X_test = X_test_df[['CRIM', 'NOX', 'INDUS','RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT','ZN','CHAS','RAD']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fit several ML algorithms and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model: Simple Linear Regression\n",
    "LR_model = LinearRegression().fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Coefficients\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.bar(np.arange(LR_model.coef_.shape[0]), LR_model.coef_)\n",
    "plt.xticks(np.arange(LR_model.coef_.shape[0]), X_train.columns, rotation='vertical')\n",
    "plt.xlim([-1, LR_model.coef_.shape[0]])\n",
    "plt.title(\"Linear Regression model coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting both train and test sets to evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "preds_test = LR_model.predict(X_test)\n",
    "preds_train = LR_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It also interesting to take a look how the predicted points relate to real ones.\n",
    "# All the points should lie on the black dotted line assuming that our model is perfect\n",
    "plt.scatter(Y_train, preds_train, label=\"Train\")\n",
    "plt.scatter(Y_test, preds_test, c=\"r\", label=\"Test\")\n",
    "plt.xlabel(\"Real price, $\")\n",
    "plt.ylabel(\"Predicted price, $\")\n",
    "plt.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=3, label=\"Ideal\")\n",
    "plt.legend(loc=\"lower right\", frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our model according to three different metrics:\n",
    "    - MAE (Mean Absolute Error)\n",
    "    - RMSE (Root Mean Squared Error)\n",
    "    - R2 (R Squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate model and store scores\n",
    "LR_score_MAE = cross_val_score(LR_model, X_train, Y_train, cv=5, scoring='neg_mean_absolute_error').mean().round(2)\n",
    "LR_score_MSE = cross_val_score(LR_model, X_train, Y_train, cv=5, scoring='neg_mean_squared_error').mean().round(2)\n",
    "LR_score_R2 = cross_val_score(LR_model, X_train, Y_train, cv=5, scoring='r2').mean().round(2)\n",
    "\n",
    "print('MAE (CV):',LR_score_MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable Selection Challenge:** Try out other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### COMPLETE THE BELOW ###\n",
    "##########################\n",
    "\n",
    "# Name of model\n",
    "_______ = model().fit(X_train, Y_train)\n",
    "\n",
    "# Cross-validate model and store scores\n",
    "_____score_MAE = cross_val_score(_______, X_train, Y_train, cv=5, scoring='neg_mean_absolute_error').mean().round(2)\n",
    "_____score_MSE = cross_val_score(_______, X_train, Y_train, cv=5, scoring='neg_mean_squared_error').mean().round(2)\n",
    "_____score_R2 = cross_val_score(_______, X_train, Y_train, cv=5, scoring='r2').mean().round(2)\n",
    "\n",
    "print('MAE (CV):',____score_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### COMPLETE THE BELOW ###\n",
    "##########################\n",
    "\n",
    "# Name of model\n",
    "_______ = model().fit(X_train, Y_train)\n",
    "\n",
    "# Cross-validate model and store scores\n",
    "_____score_MAE = cross_val_score(_______, X_train, Y_train, cv=5, scoring='neg_mean_absolute_error').mean().round(2)\n",
    "_____score_MSE = cross_val_score(_______, X_train, Y_train, cv=5, scoring='neg_mean_squared_error').mean().round(2)\n",
    "_____score_R2 = cross_val_score(_______, X_train, Y_train, cv=5, scoring='r2').mean().round(2)\n",
    "\n",
    "print('MAE (CV):',____score_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### COMPLETE THE BELOW ###\n",
    "##########################\n",
    "\n",
    "# Name of model\n",
    "_______ = model().fit(X_train, Y_train)\n",
    "\n",
    "# Cross-validate model and store scores\n",
    "_____score_MAE = cross_val_score(_______, X_train, Y_train, cv=5, scoring='neg_mean_absolute_error').mean().round(2)\n",
    "_____score_MSE = cross_val_score(_______, X_train, Y_train, cv=5, scoring='neg_mean_squared_error').mean().round(2)\n",
    "_____score_R2 = cross_val_score(_______, X_train, Y_train, cv=5, scoring='r2').mean().round(2)\n",
    "\n",
    "print('MAE (CV):',____score_MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the best model, let's compare the performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### COMPLETE THE BELOW ###\n",
    "##########################\n",
    "\n",
    "# Collect all model score results\n",
    "models = [('__________', ____score_MAE, ____score_MSE, ____score_R2),   \n",
    "          ('__________', ____score_MAE, ____score_MSE, ____score_R2),   \n",
    "          ('__________', ____score_MAE, ____score_MSE, ____score_R2),\n",
    "          ('__________', ____score_MAE, ____score_MSE, ____score_R2), \n",
    "          ('__________', ____score_MAE, ____score_MSE, ____score_R2)\n",
    "         ]\n",
    "\n",
    "# Gather in a DataFrame\n",
    "result = pd.DataFrame(data = models, columns=['Model', 'MAE', 'MSE', 'R2'])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest performs well, let's further fine-tune it to see if it can do even better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at parameters used by our current forest\n",
    "RF_model = RandomForestRegressor().fit(X_train, Y_train) # fit base model \n",
    "print('Parameters currently in use in Random Forest:\\n')\n",
    "pprint(RF_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to fine-tune the following :\n",
    "    - n_estimators = number of trees in the foreset\n",
    "    - max_features = max number of features considered for splitting a node\n",
    "    - max_depth = max number of levels in each decision tree\n",
    "    - min_samples_split = min number of data points placed in a node before the node is split\n",
    "    - min_samples_leaf = min number of data points allowed in a leaf node\n",
    "    - bootstrap = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# Random search of parameters, using 4 fold cross validation, \n",
    "RF_RS = RandomizedSearchCV(estimator = RF_model, param_distributions = random_grid, n_iter = 50, cv = 4, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "RF_RS_model = RF_RS.fit(X_train, Y_train).best_estimator_\n",
    "\n",
    "RF_RS_score_MAE = cross_val_score(RF_RS_model, X_train, Y_train, cv=5, scoring='neg_mean_absolute_error').mean().round(2)\n",
    "RF_RS_score_MSE = cross_val_score(RF_RS_model, X_train, Y_train, cv=5, scoring='neg_mean_squared_error').mean().round(2)\n",
    "RF_RS_score_R2 = cross_val_score(RF_RS_model, X_train, Y_train, cv=5, scoring='r2').mean().round(2)\n",
    "\n",
    "print('MAE (CV):',RF_RS_score_MAE)\n",
    "print(RF_RS_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine-Tuning Challenge:** Run random search on XGB as well. Or try another hyper-parameter method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### INSERT CODE HERE ###\n",
    "########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Suppose Random Forest performed the best. \n",
    "Let's see what variables were the most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising feature importance as per the fine tuned RFR fitting result\n",
    "\n",
    "##########################\n",
    "### COMPLETE THE BELOW ###\n",
    "##########################\n",
    "# Replace _______ by your random forest model\n",
    "\n",
    "# Get Feature Importance and sort\n",
    "col = list(X_test.columns)\n",
    "sorted(zip(________.feature_importances_,col),reverse=True) \n",
    "\n",
    "# Import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Create DataFrame\n",
    "feature_imp = pd.DataFrame(sorted(zip(________.feature_importances_,col)), columns=['Value','Features']) \n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.barplot(x=\"Value\", y=\"Features\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('Relative Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final Evaluation\n",
    "Y_pred = ________.predict(X_test)\n",
    "# Check output\n",
    "print(\"Prediction:\",Y_pred)\n",
    "print(\"Actual:\",Y_test)\n",
    "\n",
    "# Calculate Metrics\n",
    "_____score_MAE_test = mean_absolute_error(Y_test, Y_pred).round(2)\n",
    "_____score_MSE_test = mean_squared_error(Y_test, Y_pred).round(2)\n",
    "correlation_matrix = np.corrcoef(Y_test, Y_pred)\n",
    "______score_r2_test = ((correlation_matrix[0,1])**2).round(2)\n",
    "\n",
    "# Note that the dataset is tiny and hence testing on an even smaller sample may not be interpretable\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"MAE Test Score:\", _____score_MAE_test)\n",
    "print(\"MSE Test Score:\", ______score_MSE_test)\n",
    "print(\"R2 Test Score:\", ______score_r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In addition, we can check the Partial Dependence plot of a chosen variable\n",
    "# check for NOX (the first feature of X gets index [0], and NOX is the second hence \"features = [1]\")\n",
    "plot_partial_dependence(estimator = _____, X = X_train, features = [1] ,target='PRICE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
